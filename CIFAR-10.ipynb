{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchbearer\n",
    "import Padam\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from models import *\n",
    "\n",
    "# Parameters setting\n",
    "lr = 0.1\n",
    "partial = 1/8\n",
    "weight_decay = 5e-4\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "net = 'resnet'\n",
    "betas = (beta1, beta2)\n",
    "\n",
    "method = 'padam'\n",
    "\n",
    "# Data preparing\n",
    "print('Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "if net == 'vggnet':\n",
    "    from models import vgg\n",
    "    model = vgg.VGG('VGG16', num_classes = 10)\n",
    "elif net == 'resnet':\n",
    "    from models import resnet\n",
    "    model = resnet.ResNet18(num_classes = 10)\n",
    "elif net == 'wideresnet':\n",
    "    from models import wideresnet\n",
    "    model = wideresnet.WResNet_cifar10(num_classes = 10, depth=16, multiplier=4)\n",
    "else:\n",
    "    print ('Network undefined!')\n",
    "print('Using architecture: '+net)\n",
    "\n",
    "if method == 'padam':\n",
    "    optimiser = Padam.Padam(model.parameters(), lr=lr, partial = partial , weight_decay =weight_decay, betas =betas)\n",
    "elif method == 'adam':\n",
    "    optimiser = optim.Adam(model.parameters(),lr = lr , betas = betas,weight_decay = weight_decay, amsgrad = False)\n",
    "elif method == 'amsgrad':\n",
    "    optimiser = optim.Adam(model.parameters(),lr = lr , betas = betas,weight_decay = weight_decay, amsgrad = True)\n",
    "elif method == 'SGD':\n",
    "    optimiser = optim.SGD(model.parameters(),lr = lr, momentum=0.9, weight_decay = weight_decay)\n",
    "else:\n",
    "    print('Undefined optimizer')\n",
    "print('Using Optimizer: '+method)    \n",
    "\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy','top_5_acc']).cuda()\n",
    "\n",
    "# Provide the data to the trial\n",
    "trial.with_generators(trainloader, val_generator=testloader ,test_generator=testloader)\n",
    "\n",
    "# Run N epochs of training\n",
    "epochs=100\n",
    "result1 =trial.run(epochs)\n",
    "\n",
    "# test the performance\n",
    "results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
    "print(results)\n",
    "\n",
    "        \n",
    " \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to create a csv file of loss, acc, etc.\n",
    "import pandas as pd\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "for i in range(epochs):\n",
    "    train_loss.append(result1[i]['loss'])\n",
    "    train_acc.append(result1[i]['acc'])\n",
    "    test_loss.append(result1[i]['val_loss'])\n",
    "    test_acc.append(result1[i]['val_acc'])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'train_loss':train_loss,\n",
    "    'train_acc':train_acc,\n",
    "    'test_loss':test_loss,\n",
    "    'test_acc':test_acc\n",
    "    \n",
    "})\n",
    "\n",
    "df.to_csv('result.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
